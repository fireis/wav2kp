{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd08fd6de9d0bfe166eadfd2b806920a886e6c2c286fb4708dbd1d86a030e84ebcf",
   "display_name": "Python 3.7.10 64-bit ('wav2kp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Filipe\\.conda\\envs\\wav2kp\\lib\\site-packages\\torchaudio\\extension\\extension.py:13: UserWarning: torchaudio C++ extension is not available.\n  warnings.warn('torchaudio C++ extension is not available.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from data.base_data_module import BaseDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([80, 1600, 721])\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = np.load(\"dataset/Train.npy\", allow_pickle=True)\n",
    "# test_dataset = np.load(\"dataset/Test.npy\", allow_pickle=True)\n",
    "# val_dataset = np.load(\"dataset/Val.npy\", allow_pickle=True)\n",
    "\n",
    "train_keypoints = np.load(\"dataset/Train_keypoints.npy\",  allow_pickle=True)\n",
    "test_keypoints = np.load(\"dataset/Test_keypoints.npy\",  allow_pickle=True)\n",
    "val_keypoints = np.load(\"dataset/Val_keypoints.npy\",  allow_pickle=True)\n",
    "\n",
    "train_mfccs = torch.load(\"dataset/Train_mfccs.pt\" )\n",
    "test_mfccs = torch.load(\"dataset/Test_mfccs.pt\" )\n",
    "val_mfccs = torch.load(\"dataset/Val_mfccs.pt\" )\n",
    "\n",
    "train_mfccs_not_transp = torch.load(\"dataset/Train_mfccs.pt\" )\n",
    "train_mfccs_not_transp = torch.transpose(train_mfccs_not_transp, 2, 1)\n",
    "\n",
    "train_set  = BaseDataset(data=train_mfccs, targets=train_keypoints)\n",
    "\n",
    "print(train_mfccs_not_transp.shape)\n",
    "train_set  = BaseDataset(data=train_mfccs_not_transp, targets=train_keypoints)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set)\n",
    "# test_loader = DataLoader(test_dataset)\n",
    "# val_loader = DataLoader(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_keypoints = np.load(\"dataset/Train_keypoints.npy\",  allow_pickle=True)\n",
    "\n",
    "\n",
    "train_mfccs = torch.load(\"dataset/Train_mfccs.pt\" )\n",
    "\n",
    "\n",
    "train_mfccs_not_transp = torch.load(\"dataset/Train_mfccs.pt\" )\n",
    "train_mfccs_not_transp = torch.transpose(train_mfccs_not_transp, 2, 1)\n",
    "\n",
    "train_set  = BaseDataset(data=train_mfccs, targets=train_keypoints)\n",
    "train_set_nt  = BaseDataset(data=train_mfccs_not_transp, targets=train_keypoints)\n",
    "\n",
    "train_loader = DataLoader(train_set)\n",
    "train_loader_nt = DataLoader(train_set_nt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input_size = train_set[0][0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2, dnn_shape=1000):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dnn_shape = dnn_shape\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.dnn_shape, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        #print(f\"input.view(len(input) {input.view(len(input), self.batch_size, -1).shape}\")\n",
    "        # lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        lstm_out, self.hidden = self.lstm(input)\n",
    "        #print(lstm_out.shape)\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        # y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        y_pred = self.linear(lstm_out)\n",
    "        #print(f\"y_pred.shape in net: {y_pred.shape}\")\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        scheduler = optim.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, y_batch = batch\n",
    "        #print(f\" X_batch:{X_batch.shape}, y_batch: {y_batch.shape}\")\n",
    "        y_pred = self.forward(X_batch)\n",
    "        #print(f\"y_pred.shape: {y_pred.shape}, y_batch.shape(): {y_batch.shape}\")\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss = loss_fn(y_pred, y_batch.float())\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        # loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        X_batch, y_batch = batch\n",
    "        y_pred = self.forward(X_batch)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=800, gamma=0.5)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "model = LSTM(1600, 1000, batch_size=20, output_dim=136, num_layers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name   | Type   | Params\n",
      "----------------------------------\n",
      "0 | lstm   | LSTM   | 10.4 M\n",
      "1 | linear | Linear | 136 K \n",
      "----------------------------------\n",
      "10.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "10.5 M    Total params\n",
      "42.177    Total estimated model params size (MB)\n",
      "Epoch 999: 100%|██████████| 80/80 [00:06<00:00, 12.50it/s, loss=0.0028, v_num=68, train_loss_step=0.00162, train_loss_epoch=0.00302]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if True:\n",
    "    logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(logger=logger, weights_save_path=\"training/logs\", gpus=1 )\n",
    "\n",
    "    trainer.fit(model, train_loader)\n",
    "    # trainer.test(model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "# Here we define our model as a class\n",
    "class LSTM(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2, dnn_shape=1000):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dnn_shape = dnn_shape\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.dnn_shape, output_dim)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        #print(f\"input.view(len(input) {input.view(len(input), self.batch_size, -1).shape}\")\n",
    "        # lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
    "        lstm_out, self.hidden = self.lstm(input)\n",
    "        #print(lstm_out.shape)\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        # y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
    "        y_pred = self.linear(lstm_out)\n",
    "        #print(f\"y_pred.shape in net: {y_pred.shape}\")\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        scheduler = optim.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_batch, y_batch = batch\n",
    "        #print(f\" X_batch:{X_batch.shape}, y_batch: {y_batch.shape}\")\n",
    "        y_pred = self.forward(X_batch)\n",
    "        #print(f\"y_pred.shape: {y_pred.shape}, y_batch.shape(): {y_batch.shape}\")\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss = loss_fn(y_pred, y_batch.float())\n",
    "        # criterion = nn.BCEWithLogitsLoss()\n",
    "        # loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return {'loss': loss}\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        X_batch, y_batch = batch\n",
    "        y_pred = self.forward(X_batch)\n",
    "        \n",
    "        return {'loss': loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.01)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=800, gamma=0.5)\n",
    "\n",
    "        return [optimizer], [scheduler]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(1600, 100, batch_size=80, output_dim=136, num_layers=1, dnn_shape=100)\n",
    "if True:\n",
    "    logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "\n",
    "\n",
    "    trainer = pl.Trainer(logger=logger, weights_save_path=\"training/logs\", gpus=1 )\n",
    "\n",
    "    trainer.fit(model, train_loader)\n",
    "    # trainer.test(model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM.load_from_checkpoint(\"training/logs/default/version_71/checkpoints/epoch=999-step=79999.ckpt\",  input_dim=1600, hidden_dim=100, batch_size=80, output_dim=136, num_layers=1, dnn_shape=100)\n",
    "# C:\\studies\\wav2kp\\training\\logs\\default\\version_71\\checkpoints\\epoch=999-step=79999.ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_keypoints(keypoints, max_size=(256, 256)):\n",
    "    # multiply all x and y coordinates by the corresponding axis max\n",
    "    # this is defined on the image processing stage and should be the\n",
    "    # inverse of the scale_keypoints function\n",
    "    for p in range(0, 136, 2):\n",
    "        keypoints[:, :, p] = keypoints[:, :, p] * max_size[0]\n",
    "        keypoints[:, :, p+1] = keypoints[:, :, p+1] * max_size[1]\n",
    "    \n",
    "    \n",
    "    return keypoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_train = model(train_mfccs)\n",
    "inf_train = rescale_keypoints(inf_train)\n",
    "inf_val = model(val_mfccs)\n",
    "inf_val = rescale_keypoints(inf_val)\n",
    "inf_test = model(test_mfccs)\n",
    "inf_test = rescale_keypoints(inf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from PIL import Image, ImageDraw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "86.52184295654297"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "source": [
    "inf_train[0,0,10].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([136])\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.abspath(\"\") + \"/docs/train_val_test_dist.xlsx\"\n",
    "train_test_dist = pd.read_excel(file_path)\n",
    "\n",
    "for inf_set, set_name in zip([inf_train, inf_val, inf_test], [\"Train\", \"Val\", \"Test\"]):\n",
    "    \n",
    "    file_names = sorted(train_test_dist[train_test_dist.set == set_name].video.unique())    \n",
    "\n",
    "    for inst in inf_train:\n",
    "        for sample in inst:\n",
    "            print(sample.shape)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(frames, file_name, max_size=(256, 256)):\n",
    "    \n",
    "    for idx, frame in zip(range(0, len(frames)), frames):\n",
    "        # print(frame.shape)\n",
    "        img_d = Image.new(\"RGB\", (max_size[0], max_size[1]) )\n",
    "\n",
    "        draw = ImageDraw.Draw(img_d)\n",
    "        points = np.empty([68, 2], dtype=int)\n",
    "        # frame = frame.detach().numpy()\n",
    "        for p in range(0, 136, 2):\n",
    "            current_coord = int(p/2)\n",
    "            points[current_coord, 0] = frame[p]\n",
    "            points[current_coord, 1] = frame[p+1]\n",
    "            draw.ellipse((points[current_coord, 0], points[current_coord, 1], points[current_coord, 0] + 1, points[current_coord, 1] + 1), fill='white', outline='white')\n",
    "\n",
    "\n",
    "        img_d.save(f\"{file_name}/{idx:05}.png\")\n",
    "        \n",
    "frames = inf_train[0,:].detach()\n",
    "draw_keypoints(frames, \"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n",
      "(68, 2)\n"
     ]
    }
   ],
   "source": [
    "from utils.v2v_utils import *\n",
    "def draw_face_edges_v2v(frames, file_name):\n",
    "    \n",
    "    part_list = [[list(range(0, 17)) + list(range(68, 83)) + [0]],  # face\n",
    "                 [range(17, 22)],  # right eyebrow\n",
    "                 [range(22, 27)],  # left eyebrow\n",
    "                 [[28, 31], range(31, 36), [35, 28]],  # nose\n",
    "                 [[36, 37, 38, 39], [39, 40, 41, 36]],  # right eye\n",
    "                 [[42, 43, 44, 45], [45, 46, 47, 42]],  # left eye\n",
    "                 [range(48, 55), [54, 55, 56, 57, 58, 59, 48]],  # mouth\n",
    "                 [range(60, 65), [64, 65, 66, 67, 60]]  # tongue\n",
    "                 ]\n",
    "\n",
    "    w, h = 256, 256\n",
    "    edge_len = 3  # interpolate 3 keypoints to form a curve when drawing edges\n",
    "    # edge map for face region from keypoints\n",
    "    # im_edges = np.zeros((h, w), np.uint8) # edge map for all edges\n",
    "\n",
    "\n",
    "    color = 0\n",
    "    color_edge = (255, 255, 255)\n",
    "\n",
    "    for idx, frame in zip(range(0, len(frames)), frames):\n",
    "\n",
    "        im_edges = np.full((h, w), color, np.uint8)\n",
    "        keypoints = np.empty([68, 2], dtype=int)\n",
    "        # frame = frame.detach().numpy()\n",
    "        for p in range(0, 136, 2):\n",
    "            current_coord = int(p/2)\n",
    "            keypoints[current_coord, 0] = frame[p]\n",
    "            keypoints[current_coord, 1] = frame[p+1]\n",
    "        print(keypoints.shape)\n",
    "    \n",
    "        # from v2v\n",
    "        pts = keypoints[:17, :].astype(np.int32)\n",
    "        baseline_y = (pts[0, 1] + pts[-1, 1]) / 2\n",
    "        upper_pts = pts[1:-1, :].copy()\n",
    "        upper_pts[:, 1] = baseline_y + (baseline_y - upper_pts[:, 1]) * 2 // 3\n",
    "        keypoints = np.vstack((keypoints, upper_pts[::-1, :]))\n",
    "\n",
    "        for edge_list in part_list:\n",
    "            for edge in edge_list:\n",
    "\n",
    "                # im_edge = np.full((h, w), color, np.uint8)\n",
    "                im_edge = np.zeros((h, w), np.uint8)  # edge map for the current edge\n",
    "                for i in range(0, max(1, len(edge) - 1),\n",
    "                            edge_len - 1):  # divide a long edge into multiple small edges when drawing\n",
    "                    sub_edge = edge[i:i + edge_len]\n",
    "                    x = keypoints[sub_edge, 0]\n",
    "                    y = keypoints[sub_edge, 1]\n",
    "\n",
    "                    curve_x, curve_y = interpPoints(x, y)  # interp keypoints to get the curve shape\n",
    "\n",
    "                    drawEdge(im_edges, curve_x, curve_y, color=color_edge)\n",
    "\n",
    "        # np.save(im_edges,A_path.replace(\"txt\", \"png\").replace(\"keypoints\", \"gambi_image\"))\n",
    "        im_edges = Image.fromarray(im_edges)\n",
    "        # im_edges = resize_img(im_edges, keypoints)\n",
    "        im_edges.save(f\"{file_name}/{idx:05}.png\")\n",
    "        # Image.fromarray(crop(im_edges, keypoints)).save(A_path.replace(\"txt\", \"png\").replace(\"keypoints\", \"gambi_image\"))\n",
    "    return\n",
    "\n",
    "draw_face_edges_v2v(frames, \"results/v2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136])"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "np.array(range(1, 137))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1,  1],\n",
       "       [ 2,  2],\n",
       "       [ 3,  3],\n",
       "       [ 4,  4],\n",
       "       [ 5,  5],\n",
       "       [ 6,  6],\n",
       "       [ 7,  7],\n",
       "       [ 8,  8],\n",
       "       [ 9,  9],\n",
       "       [10, 10],\n",
       "       [11, 11],\n",
       "       [12, 12],\n",
       "       [13, 13],\n",
       "       [14, 14],\n",
       "       [15, 15],\n",
       "       [16, 16],\n",
       "       [17, 17],\n",
       "       [18, 18],\n",
       "       [19, 19],\n",
       "       [20, 20],\n",
       "       [21, 21],\n",
       "       [22, 22],\n",
       "       [23, 23],\n",
       "       [24, 24],\n",
       "       [25, 25],\n",
       "       [26, 26],\n",
       "       [27, 27],\n",
       "       [28, 28],\n",
       "       [29, 29],\n",
       "       [30, 30],\n",
       "       [31, 31],\n",
       "       [32, 32],\n",
       "       [33, 33],\n",
       "       [34, 34],\n",
       "       [35, 35],\n",
       "       [36, 36],\n",
       "       [37, 37],\n",
       "       [38, 38],\n",
       "       [39, 39],\n",
       "       [40, 40],\n",
       "       [41, 41],\n",
       "       [42, 42],\n",
       "       [43, 43],\n",
       "       [44, 44],\n",
       "       [45, 45],\n",
       "       [46, 46],\n",
       "       [47, 47],\n",
       "       [48, 48],\n",
       "       [49, 49],\n",
       "       [50, 50],\n",
       "       [51, 51],\n",
       "       [52, 52],\n",
       "       [53, 53],\n",
       "       [54, 54],\n",
       "       [55, 55],\n",
       "       [56, 56],\n",
       "       [57, 57],\n",
       "       [58, 58],\n",
       "       [59, 59],\n",
       "       [60, 60],\n",
       "       [61, 61],\n",
       "       [62, 62],\n",
       "       [63, 63],\n",
       "       [64, 64],\n",
       "       [65, 65],\n",
       "       [66, 66],\n",
       "       [67, 67],\n",
       "       [68, 68]])"
      ]
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "orig = np.array(list(zip(list(range(1, 69)), list(range(1, 69)))))\n",
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,\n",
       "         9,  9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "        17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23, 24, 24,\n",
       "        25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30, 31, 31, 32, 32,\n",
       "        33, 33, 34, 34, 35, 35, 36, 36, 37, 37, 38, 38, 39, 39, 40, 40,\n",
       "        41, 41, 42, 42, 43, 43, 44, 44, 45, 45, 46, 46, 47, 47, 48, 48,\n",
       "        49, 49, 50, 50, 51, 51, 52, 52, 53, 53, 54, 54, 55, 55, 56, 56,\n",
       "        57, 57, 58, 58, 59, 59, 60, 60, 61, 61, 62, 62, 63, 63, 64, 64,\n",
       "        65, 65, 66, 66, 67, 67, 68, 68]])"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "transp = np.reshape(orig, (1, 136))\n",
    "transp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}